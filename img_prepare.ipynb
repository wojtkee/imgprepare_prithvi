{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import tifffile\n",
    "from osgeo import gdal\n",
    "# from skimage import io \n",
    "# from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import  json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_transposition(img):\n",
    "\n",
    "    bands=[0, 1, 2, 7, 8, 9]\n",
    "    # img1=np.transpose(img[0,bands,:,:],(1,2,0))\n",
    "    # img2=np.transpose(img[1,bands,:,:],(1,2,0))\n",
    "    # img3=np.transpose(img[2,bands,:,:],(1,2,0))\n",
    "    img_shape=img.shape\n",
    "    params=np.zeros(6)\n",
    "    new_img_time_series = np.empty((0, img_shape[1], img_shape[2], img_shape[3]), dtype=img.dtype)\n",
    "    for i in range(img_shape[1]):\n",
    "\n",
    "        params[0]=np.mean(img[i,0,:,:])\n",
    "        params[1]=np.mean(img[i,1,:,:])\n",
    "        params[2]=np.mean(img[i,2,:,:])\n",
    "        params[3]=np.median(img[i,0,:,:])\n",
    "        params[4]=np.median(img[i,1,:,:])\n",
    "        params[5]=np.median(img[i,2,:,:])\n",
    "        \n",
    "        if np.all(params[0:3] < 4000) and np.all(params[3:6] > 200):\n",
    "            new_img_time_series = np.vstack((new_img_time_series, img[i,:,:,:][np.newaxis]))\n",
    "\n",
    "\n",
    "\n",
    "    new_img_time_series = np.array(new_img_time_series)\n",
    "    new_shape=new_img_time_series.shape\n",
    "\n",
    "    # print(new_shape)\n",
    "    middle_index = new_shape[0] // 2\n",
    "    img1 = np.transpose(new_img_time_series[0, bands, :, :], (1, 2, 0))\n",
    "    img2 = np.transpose(new_img_time_series[middle_index, bands, :, :], (1, 2, 0))\n",
    "    img3 = np.transpose(new_img_time_series[-1, bands, :, :], (1, 2, 0))\n",
    "\n",
    "\n",
    "    # merged_img=np.concatenate([img1,img2,img3], axis=2)\n",
    "    merged_img =np.dstack((img1,img2,img3))\n",
    "    # transposed_img = np.transpose(merged_img, (2,0,1))\n",
    "    # print(transposed_img.shape)\n",
    "    return merged_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(image, fold_values, id_patch_to_fold,parcel_id_nb):\n",
    "        bands=[0, 1, 2, 7, 8, 9]\n",
    "        normalized_image = np.zeros_like(image, dtype=np.float32)\n",
    "        for channel in range(6):  # 3x6 kanałów\n",
    "            # print(image[0,0:9,0:9])            \n",
    "            normalized_image[:, :, channel] = (image[:, :, channel] - fold_values[id_patch_to_fold[parcel_id_nb]]['mean'][bands[channel]]) / fold_values[id_patch_to_fold[parcel_id_nb]]['std'][bands[channel]]\n",
    "            normalized_image[:, :, channel+6] = (image[:, :, channel+6] - fold_values[id_patch_to_fold[parcel_id_nb]]['mean'][bands[channel]]) / fold_values[id_patch_to_fold[parcel_id_nb]]['std'][bands[channel]]\n",
    "            normalized_image[:, :, channel+12] = (image[:, :, channel+12] - fold_values[id_patch_to_fold[parcel_id_nb]]['mean'][bands[channel]]) / fold_values[id_patch_to_fold[parcel_id_nb]]['std'][bands[channel]]\n",
    "            # print(normalized_image[0,0:9,0:9]) \n",
    "            # dupamatrix=normalized_image[0,0:9,0:9]\n",
    "            \n",
    "        return normalized_image    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_img(image, size):\n",
    "\n",
    "    if len(image.shape)==2:\n",
    "        height, width=image.shape\n",
    "        channels=1\n",
    "    elif len(image.shape)==3:\n",
    "        height,width, channels=image.shape\n",
    "    else:\n",
    "        raise ValueError(\"Unsuported image shape\")\n",
    "\n",
    "    padded_img=np.zeros((size[0],size[1], channels),dtype=np.float32)\n",
    "    y_offset=(size[0]-height) // 2\n",
    "    x_offset=(size[0]-width) // 2\n",
    "\n",
    "\n",
    "    if channels==1:\n",
    "        padded_img[y_offset:y_offset+height,x_offset:x_offset+width,0]=image\n",
    "    else:\n",
    "        padded_img[y_offset:y_offset+height,x_offset:x_offset+width,:]=image\n",
    "\n",
    "    return padded_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proces_img(dataset_path, mask_path, save_path, prefix, fold_values, id_patch_to_fold,validation_fold_nb,upscaling_img):\n",
    "    old_save=save_path\n",
    "    training_i=0\n",
    "    validation_i=0\n",
    "    processed_files_training = []\n",
    "    processed_files_validation = []\n",
    "    size=(224,224)\n",
    "    val_save_path= os.path.join(save_path, 'validation_chips')\n",
    "    train_save_patch=os.path.join(save_path, 'training_chips')\n",
    "\n",
    "    for file_name in os.listdir(dataset_path):\n",
    "        \n",
    "        if file_name.endswith(\".npy\"):\n",
    "\n",
    "            match = re.search(r'S2_(\\d{2})(\\d{3}).npy', file_name)\n",
    "            yyy = match.group(1)\n",
    "            xxx = match.group(2)\n",
    "            mask_pth=os.path.join(mask_path,f\"TARGET_{yyy}{xxx}.npy\")\n",
    "            parcel_id_nb=int(yyy + xxx)\n",
    "\n",
    "\n",
    "\n",
    "            if match and os.path.exists(mask_pth):\n",
    "                # print(\"dupa\")\n",
    "                if id_patch_to_fold[parcel_id_nb]==validation_fold_nb:\n",
    "                    save_path =val_save_path\n",
    "                else:\n",
    "                    save_path = train_save_patch\n",
    "\n",
    "                \n",
    "\n",
    "\n",
    "                data=np.load(os.path.join(dataset_path,file_name))\n",
    "\n",
    "                new_file_name=f\"{prefix}_{xxx}_{yyy}_merged.tif\"\n",
    "                # np.save(os.path.join(save_path, new_file_name), data)\n",
    "                img1=img_transposition(data)\n",
    "                img2=normalize_image(img1,fold_values,id_patch_to_fold,parcel_id_nb)\n",
    "                # img2=img1\n",
    "\n",
    "                \n",
    "                if upscaling_img:\n",
    "                    imgscal=cv2.resize(img2,size,interpolation=cv2.INTER_LANCZOS4)\n",
    "                else:\n",
    "                    imgscal=resize_img(img2,size)\n",
    "                # print(imgscal.shape)\n",
    "                # tifffile.imwrite(os.path.join(save_path, new_file_name), img1)\n",
    "                # cv2.imwrite(os.path.join(save_path, new_file_name + \".tif\"), img1.astype(np.int16))\n",
    "\n",
    "                driver = gdal.GetDriverByName('GTiff')  # Wybór sterownika dla formatu pliku TIFF\n",
    "                image_height, image_width, num_bands = imgscal.shape  # Wymiary obrazu i liczba kanałów\n",
    "\n",
    "                # Tworzenie nowego pliku rastrowego\n",
    "                output_path = os.path.join(save_path, new_file_name)\n",
    "   \n",
    "                # output_dataset = driver.Create(output_path, image_width, image_height, num_bands, gdal.GDT_Float32)  # Tworzenie nowego pliku TIFF z 18 kanałami\n",
    "                output_dataset = driver.Create(output_path, image_width, image_height, num_bands, gdal.GDT_Float32)  # Tworzenie nowego pliku TIFF z 18 kanałami\n",
    "\n",
    "                \n",
    "\n",
    "\n",
    "                # Zapisywanie danych obrazu do pliku rastrowego\n",
    "                for band_idx in range(num_bands):\n",
    "                    output_dataset.GetRasterBand(band_idx + 1).WriteArray(imgscal[:, :, band_idx].astype(np.float32))  # Zapisywanie danych do kolejnych kanałów\n",
    "\n",
    "\n",
    "                # tifffile.imwrite(os.path.join(save_path, new_file_name), img1,metadata=tags)\n",
    "                mask=np.load(mask_pth)\n",
    "                \n",
    "                extracted_layer=mask[0,:,:]\n",
    "\n",
    "\n",
    "\n",
    "                reduced_mask = extracted_layer.copy()\n",
    "                # print(reduced_mask.shape)\n",
    "                mask_13_to_18 = (extracted_layer >= 13) & (extracted_layer <= 18)\n",
    "                mask_13_to_18_indices = np.where(mask_13_to_18)\n",
    "                reduced_mask[mask_13_to_18_indices] = 12\n",
    "                reduced_mask[np.where(extracted_layer==19)]=0\n",
    "                reduced_mask[np.where(extracted_layer==0)]=13\n",
    "\n",
    "                reduced_mask[np.where(extracted_layer<0)]=13\n",
    "\n",
    "                \n",
    "\n",
    "                \n",
    "                # reduced_mask(extracted_layer == 19) = 13\n",
    "                new_mask_name=f\"{prefix}_{xxx}_{yyy}.mask.tif\"\n",
    "                # np.save(os.path.join(save_path, new_mask_name), extracted_layer) \n",
    "                \n",
    "                if upscaling_img:\n",
    "                    maskscal=cv2.resize(reduced_mask,size,interpolation=cv2.INTER_NEAREST)\n",
    "                else:\n",
    "\n",
    "                    maskscal=resize_img(reduced_mask,size)\n",
    "\n",
    "                maskscal_str=maskscal.astype(np.int16)\n",
    "\n",
    "                tifffile.imwrite(os.path.join(save_path, new_mask_name), maskscal_str)  \n",
    "\n",
    "                if id_patch_to_fold[parcel_id_nb]==validation_fold_nb:\n",
    "                    processed_files_validation.append(f\"{prefix}_{xxx}_{yyy}\")\n",
    "                    validation_i+=1\n",
    "                else:\n",
    "                    processed_files_training.append(f\"{prefix}_{xxx}_{yyy}\")\n",
    "                    training_i+=1\n",
    "                \n",
    "                \n",
    "                \n",
    "    with open(os.path.join(old_save,\"validation_data.txt\"), 'w') as txt_file:\n",
    "        for file_name in processed_files_validation:\n",
    "            txt_file.write(file_name + '\\n')\n",
    "    with open(os.path.join(old_save,\"training_data.txt\"), 'w') as txt_file:\n",
    "        for file_name in processed_files_training:\n",
    "            txt_file.write(file_name + '\\n')\n",
    "    print(f\"generated training images: {training_i}\")\n",
    "    print(f\"generated validation images: {validation_i}\")\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "\n",
    "dataset_path=r'F:\\mgr_datasets\\PASTIS\\DATA_S2'\n",
    "mask_path=r'F:\\mgr_datasets\\PASTIS\\ANNOTATIONS'\n",
    "save_path=r'F:\\mgr_datasets\\multismall'\n",
    "# val_set_path=r'F:\\mgr_datasets\\multimoj\\validation_chips'\n",
    "json_path=r'F:\\mgr_datasets\\PASTIS\\NORM_S2_patch.json'\n",
    "geojson_path=r'F:\\mgr_datasets\\PASTIS\\metadata.geojson'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(json_path, 'r') as f:\n",
    "    folds_data = json.load(f)\n",
    "\n",
    "fold_values = {}\n",
    "i=1\n",
    "for fold_name, fold_data in folds_data.items():\n",
    "    mean_values = fold_data[\"mean\"]\n",
    "    std_values = fold_data[\"std\"]\n",
    "    \n",
    "    # Dodanie wartości dla aktualnego foldu do słownika\n",
    "    fold_values[i] = {\"mean\": mean_values, \"std\": std_values}\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(geojson_path, 'r') as f:\n",
    "    folds_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_patch_to_fold = {}\n",
    "for feature in folds_data['features']:\n",
    "    properties = feature['properties']\n",
    "    if 'ID_PATCH' in properties and 'Fold' in properties:\n",
    "        id_patch = properties['ID_PATCH']\n",
    "        fold = properties['Fold']\n",
    "        id_patch_to_fold[id_patch] = fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_files=os.listdir(dataset_path)\n",
    "# train_files, val_files = train_test_split(dataset_files, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_save_path = os.path.join(save_path, \"training_chips\")\n",
    "validation_save_path = os.path.join(save_path, \"validation_chips\")\n",
    "os.makedirs(training_save_path, exist_ok=True)\n",
    "os.makedirs(validation_save_path, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated training images: 1937\n",
      "generated validation images: 496\n"
     ]
    }
   ],
   "source": [
    "upscaling_img=False\n",
    "validation_fold_nb=5\n",
    "\n",
    "proces_img(dataset_path, mask_path, save_path, 'chip', fold_values,id_patch_to_fold,validation_fold_nb,upscaling_img)\n",
    "\n",
    "# Wywołaj funkcje przetwarzające obrazy i masek dla danych walidacyjnych\n",
    "\n",
    "# proces_img(dataset_path, mask_path, val_set_path, 'chip',\"validation_data.txt\",fold_values,id_patch_to_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pth=r'F:\\mgr_datasets\\multimoj\\training_chips\\chip_001_10_merged.tif'\n",
    "img=tifffile.imread(img_pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1165.9398193359375\n"
     ]
    }
   ],
   "source": [
    "print(fold_values[1]['mean'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\mgr_datasets\\PASTIS\\ANNOTATIONS\n"
     ]
    }
   ],
   "source": [
    "os.path.exists(mask_path)\n",
    "print(mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver = gdal.GetDriverByName('GTiff')\n",
    "# output_dataset = driver.Create(r'F:\\mgr_datasets\\multismall\\training_chips\\chip_000_10_merged.tif', 224, 224, 18)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
